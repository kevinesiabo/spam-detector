{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Analyse des performances du détecteur de spam\n",
        "\n",
        "Ce notebook charge le dataset et le modèle `model.pkl`, calcule des métriques et génère plusieurs visualisations: courbe ROC, courbe Precision-Recall, matrice de confusion et importance des caractéristiques (mots/bi-grammes) du modèle Logistic Regression entraîné avec TF‑IDF.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, classification_report\n",
        "\n",
        "# Chargement des données et du modèle\n",
        "csv_path = os.path.join('..', 'data', 'emails.csv') if not os.path.exists('data/emails.csv') else 'data/emails.csv'\n",
        "df = pd.read_csv(csv_path)\n",
        "X = df['texte'].astype(str)\n",
        "y = df['label'].astype(str)\n",
        "\n",
        "model = joblib.load('model.pkl')\n",
        "\n",
        "# Prédictions\n",
        "if hasattr(model, 'predict_proba'):\n",
        "    y_proba = model.predict_proba(X)[:, 1]\n",
        "else:\n",
        "    # Fallback: decision_function → sigmoid approx\n",
        "    from sklearn.preprocessing import MinMaxScaler\n",
        "    scores = model.decision_function(X)\n",
        "    y_proba = MinMaxScaler().fit_transform(scores.reshape(-1, 1)).ravel()\n",
        "\n",
        "y_pred = model.predict(X)\n",
        "print(classification_report(y, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Courbe ROC\n",
        "fpr, tpr, _ = roc_curve((y == 'spam').astype(int), y_proba)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot(fpr, tpr, label=f'ROC AUC = {roc_auc:.3f}')\n",
        "plt.plot([0,1], [0,1], 'k--', linewidth=0.8)\n",
        "plt.xlabel('FPR')\n",
        "plt.ylabel('TPR')\n",
        "plt.title('ROC')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Courbe Precision-Recall\n",
        "precision, recall, _ = precision_recall_curve((y == 'spam').astype(int), y_proba)\n",
        "plt.figure(figsize=(5,4))\n",
        "plt.plot(recall, precision)\n",
        "plt.xlabel('Recall')\n",
        "plt.ylabel('Precision')\n",
        "plt.title('Precision-Recall')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Matrice de confusion\n",
        "cm = confusion_matrix(y, y_pred, labels=['non-spam', 'spam'])\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['non-spam', 'spam'], yticklabels=['non-spam', 'spam'])\n",
        "plt.xlabel('Prédit')\n",
        "plt.ylabel('Réel')\n",
        "plt.title('Matrice de confusion')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Importance des caractéristiques (mots/bi-grammes)\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "pipe: Pipeline = model\n",
        "vectorizer: TfidfVectorizer = pipe.named_steps['tfidf']\n",
        "clf: LogisticRegression = pipe.named_steps['clf']\n",
        "\n",
        "feature_names = np.array(vectorizer.get_feature_names_out())\n",
        "coefs = clf.coef_.ravel()\n",
        "\n",
        "# Top mots pro-spam et pro-non-spam\n",
        "k = 15\n",
        "idx_top_spam = np.argsort(coefs)[-k:][::-1]\n",
        "idx_top_ham = np.argsort(coefs)[:k]\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.barh(feature_names[idx_top_spam][::-1], coefs[idx_top_spam][::-1])\n",
        "plt.title('Top features (spam)')\n",
        "plt.tight_layout()\n",
        "\n",
        "plt.subplot(1,2,2)\n",
        "plt.barh(feature_names[idx_top_ham], coefs[idx_top_ham])\n",
        "plt.title('Top features (non-spam)')\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
